{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Hourly Traffic Volume prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import datetime \n",
    "import heapq\n",
    "import time\n",
    "from sklearn.metrics import mean_squared_log_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='darkblue'>Data Preparation</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://aisgaiap.blob.core.windows.net/aiap5-assessment-data/traffic_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicate rows of date_time records\n",
    "df.drop_duplicates(subset='date_time', keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop snow_1h column since all are zero values\n",
    "df = df.drop(['snow_1h'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert rain_1h from continuous to discrete variable.\n",
    "df['rain_1h'] = df['rain_1h'].apply(lambda x: 0 if x == 0 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert clouds_all from continuous to discrete variable.\n",
    "def cloud_all_binning(value):\n",
    "    if(value <= 20):\n",
    "        return 0\n",
    "    elif(value <= 40):\n",
    "        return 1\n",
    "    elif(value <= 60):\n",
    "        return 2\n",
    "    elif(value <= 70):\n",
    "        return 3\n",
    "    elif(value <= 80):\n",
    "        return 4\n",
    "    else:\n",
    "        return 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform binning on clouds_all column\n",
    "df['clouds_all'] = df['clouds_all'].apply(lambda x: cloud_all_binning(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop temp column as there seems to be little or no correlation with the output variable\n",
    "df = df.drop(['temp'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='darkblue'>Feature Engineering</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the hour of a timestamp into a new column\n",
    "hours = df['date_time'].apply(lambda x: x.split(' ')[1].split(':')[0])\n",
    "# One-hot encoding of data\n",
    "hours = pd.get_dummies(hours).iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDayOfWeek(date):\n",
    "    int_day = datetime.datetime.strptime(date, '%Y %m %d').weekday()\n",
    "    days_mapping = {0:'Mon', 1:'Tues', 2:'Wed', 3:'Thurs', 4:'Fri', 5:'Saturday', 6:'Sunday'}\n",
    "    return (days_mapping[int_day])\n",
    "\n",
    "# Extract the day of week of a timestamp into a new column\n",
    "date = df['date_time'].apply(lambda x: x.split(' ')[0].replace('-',' '))\n",
    "day_of_week = date.apply(lambda x: getDayOfWeek(x))\n",
    "day_of_week = pd.get_dummies(day_of_week).iloc[:, 1:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='darkblue'>Model</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, [1,2]]\n",
    "y = df['traffic_volume'].values\n",
    "# Concat with the engineered features (extracted hours)\n",
    "X = pd.concat([X, pd.DataFrame(hours)], axis = 1)\n",
    "X = pd.concat([X, pd.DataFrame(day_of_week)], axis = 1)\n",
    "\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#Model engineering\\n#Tuning of n_estimators parameter\\n\\nacc_scores = []\\nnum_esti = []\\nnum_trees = np.arange(1, 280, 10) \\n\\nfor k in num_trees:\\n    rfc = RandomForestRegressor(n_estimators=k, random_state=42)\\n    predictions = rfc.fit(X_train, y_train).predict(X_test)\\n    errors = abs(y_test - predictions)\\n    mean_perc_error = 100 * (errors / y_test)\\n    accuracy = 100 - np.mean(mean_perc_error)\\n    acc_scores.append(accuracy)\\n    num_esti.append(k)\\n    \\nindexes = heapq.nlargest(10, range(len(acc_scores)), acc_scores.__getitem__)\\nn_max_score = [acc_scores[i] for i in indexes]\\nn_max_estimators = [num_esti[i] for i in indexes]\\nprint(n_max_score)\\nprint(n_max_estimators)\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#Model engineering\n",
    "#Tuning of n_estimators parameter\n",
    "\n",
    "acc_scores = []\n",
    "num_esti = []\n",
    "num_trees = np.arange(1, 280, 10) \n",
    "\n",
    "for k in num_trees:\n",
    "    rfc = RandomForestRegressor(n_estimators=k, random_state=42)\n",
    "    predictions = rfc.fit(X_train, y_train).predict(X_test)\n",
    "    errors = abs(y_test - predictions)\n",
    "    mean_perc_error = 100 * (errors / y_test)\n",
    "    accuracy = 100 - np.mean(mean_perc_error)\n",
    "    acc_scores.append(accuracy)\n",
    "    num_esti.append(k)\n",
    "    \n",
    "indexes = heapq.nlargest(10, range(len(acc_scores)), acc_scores.__getitem__)\n",
    "n_max_score = [acc_scores[i] for i in indexes]\n",
    "n_max_estimators = [num_esti[i] for i in indexes]\n",
    "print(n_max_score)\n",
    "print(n_max_estimators)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution Time: 3.22 s\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "# we will use n_estimators = 151 as it ranks among the top few in terms of accuracy score from the results of model engineering\n",
    "randForest = RandomForestRegressor(n_estimators = 151, random_state = 42)\n",
    "time_start = time.time()\n",
    "randForest.fit(X_train, y_train)\n",
    "time_end = time.time() - time_start\n",
    "print('Execution Time:', round(time_end, 3), 's')\n",
    "preds = randForest.predict(X_train)\n",
    "ypreds = randForest.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set\n",
      "Root Mean Squared Log Error = 0.172\n",
      "Accuracy Score: 89.164 %\n",
      "Test set\n",
      "Root Mean Squared Log Error = 0.177\n",
      "Accuracy Score: 88.223 %\n"
     ]
    }
   ],
   "source": [
    "# Evaluation metrics on model performance\n",
    "print('Training set')\n",
    "print('Root Mean Squared Log Error =', round(np.sqrt(mean_squared_log_error(y_train, preds)), 3))\n",
    "mean_perc_error = 100 * (abs(y_train - preds) / y_train)\n",
    "accuracy = 100 - np.mean(mean_perc_error)\n",
    "print('Accuracy Score:', round(accuracy, 3), '%')\n",
    "print('Test set')\n",
    "errors = abs(y_test - ypreds)\n",
    "print('Root Mean Squared Log Error =', round(np.sqrt(mean_squared_log_error(y_test, ypreds)), 3))\n",
    "mean_perc_error1 = 100 * (errors / y_test)\n",
    "accuracy = 100 - np.mean(mean_perc_error1)\n",
    "print('Accuracy Score:', round(accuracy, 3), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get numerical feature importances\n",
    "#feature_list = list(X.columns)\n",
    "#importances = list(randForest.feature_importances_)\n",
    "# List of tuples with variable and importance\n",
    "#feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(feature_list, importances)]\n",
    "# Sort the feature importances by most important first\n",
    "#feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "# Print out the feature and importances \n",
    "#[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances];"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
